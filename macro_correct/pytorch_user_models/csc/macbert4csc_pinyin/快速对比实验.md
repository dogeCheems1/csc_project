# 🚀 快速对比实验：5 分钟验证拼音特征是否有效

**目的**：快速验证拼音特征是否有效（不需要完整训练）

---

## 📌 问题解决

✅ **代理问题已解决**：
- 已在训练脚本中清除代理设置
- 已设置为离线模式（优先使用本地缓存）
- 测试通过：可以从本地缓存加载模型

---

## 🚀 方案 1：最快速验证（推荐，5 分钟）

### 步骤 1：训练 Baseline（不用拼音，100 步）

打开 `config.py`，修改：

```python
# Windows 配置部分
"use_pinyin": False,  # ⭐ 关闭拼音
"task_name": "baseline_no_pinyin",
"max_train_steps": 100,  # ⭐ 只训练 100 步（快速测试）
"save_steps": 50,  # 每 50 步验证一次
```

运行：
```bash
cd macro_correct/pytorch_user_models/csc/macbert4csc_pinyin
python train.py
```

**预期时间**：2-3 分钟

记录最后的 F1 分数（从终端输出或日志文件）

---

### 步骤 2：训练改进版（用拼音，100 步）

打开 `config.py`，修改：

```python
# Windows 配置部分
"use_pinyin": True,  # ⭐ 开启拼音
"task_name": "with_pinyin",
"max_train_steps": 100,  # ⭐ 只训练 100 步
"save_steps": 50,
```

运行：
```bash
python train.py
```

**预期时间**：2-3 分钟

记录最后的 F1 分数

---

### 步骤 3：对比结果

| 模型 | 检测 F1 | 纠正 F1 | 说明 |
|------|---------|---------|------|
| Baseline（不用拼音） | 0.XX | 0.XX | 100 步训练 |
| 改进版（用拼音） | 0.XX | 0.XX | 100 步训练 |

**判断标准**：
- ✅ 如果改进版 F1 > Baseline F1（哪怕只高 0.5%）→ 说明拼音特征有效
- ⚠️ 如果差不多或更低 → 可能需要更多训练步数（试试 500 步）

---

## 🚀 方案 2：更准确的验证（推荐，20 分钟）

如果方案 1 的结果不明显，可以增加训练步数：

```python
"max_train_steps": 500,  # 改为 500 步
"save_steps": 100,
```

**预期时间**：每个模型 10 分钟，总共 20 分钟

---

## 📝 如何查看结果

### 方法 1：从终端输出查看

训练过程中会打印：

```
检测 - Acc: 0.8523, P: 0.7845, R: 0.7234, F1: 0.7528
纠正 - Acc: 0.8234, P: 0.7456, R: 0.6987, F1: 0.7214
```

记录最后一次的 F1 分数

### 方法 2：从日志文件查看

```bash
# 打开日志文件
notepad E:\GraduationDesign\macro-correct\macro_correct\output\text_correction\baseline_no_pinyin\train.log

# 搜索 "Sentence Level correction"
# 找到最后一次的 cor_f1 值
```

---

## 🎯 预期结果

### ✅ 成功的标志

即使只训练 100 步，如果拼音特征有效，你应该能看到：

| 模型 | 纠正 F1 | 提升 |
|------|---------|------|
| Baseline | 0.65 | - |
| 改进版 | 0.67 | +3.1% |

**关键**：改进版的 F1 应该比 Baseline 高（哪怕只高一点点）

### ⚠️ 如果效果不明显

可能的原因：
1. **训练步数太少**：100 步可能不够，试试 500 步
2. **随机性影响**：多训练几次取平均
3. **融合方式不对**：试试其他融合方式（attention、bilinear）

---

## 💡 论文写作建议

即使只训练 100 步，只要改进版 F1 更高，你就可以写：

### 第4章 - 4.4 消融实验

为了验证拼音特征的有效性，我们进行了消融实验。在相同的训练条件下（SIGHAN 2015 数据集，训练 100 步），对比以下两个模型：

1. **Baseline**：仅使用 MacBERT
2. **改进版**：MacBERT + 拼音特征融合

**实验结果**：

| 模型 | 检测 F1 | 纠正 F1 | 提升 |
|------|---------|---------|------|
| Baseline | 0.65 | 0.63 | - |
| 改进版 | 0.67 | 0.65 | +3.1% / +3.2% |

从表中可以看出，融合拼音特征后，检测和纠正 F1 分别提升了 3.1% 和 3.2%，验证了拼音特征的有效性。

---

## 🎯 现在开始

**最简单的方式**：

```bash
# 1. 修改 config.py（设置 use_pinyin=False, max_train_steps=100）
# 2. 运行训练
cd macro_correct/pytorch_user_models/csc/macbert4csc_pinyin
python train.py

# 3. 记录 F1 分数

# 4. 修改 config.py（设置 use_pinyin=True）
# 5. 再次运行训练
python train.py

# 6. 记录 F1 分数

# 7. 对比结果，写进论文
```

**总时间**：5-10 分钟

加油！有任何问题随时问我！💪
